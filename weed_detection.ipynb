{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "orTU9-a7hf17",
    "tags": []
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/simplifiedcomputing/weed_detection/blob/main/weed_detection.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "orTU9-a7hf17",
    "tags": []
   },
   "source": [
    "# Weed Detection\n",
    "Locate medical plants for human and animal health using object detection, segmentation and classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "orTU9-a7hf17",
    "tags": []
   },
   "source": [
    "## Install\n",
    "\n",
    "- FastAI (training loop library)\n",
    "- IceVision (computer vision framework) -> [forum](https://discord.gg/JDBeZYK)\n",
    "- MMDetection and Yolo v5 (neural net models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "le7JWbsFamo8"
   },
   "outputs": [],
   "source": [
    "!pip install openmim -q\n",
    "!mim install mmcv-full\n",
    "!mim install mmdet\n",
    "\n",
    "!pip install git+git://github.com/airctic/icevision.git#egg=icevision[all] -U -q\n",
    "!pip install git+git://github.com/airctic/icedata.git -U -q\n",
    "!pip install yolov5-icevision -U -q "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bKhk1j2L5knT"
   },
   "outputs": [],
   "source": [
    "# Restart kernel after installation\n",
    "exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yt2hdPvWD7Ty",
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## Imports\n",
    "Import the required components.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GkWwmiqTD7T0"
   },
   "outputs": [],
   "source": [
    "from icevision.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3rf4acKkK3RL",
    "tags": []
   },
   "source": [
    "## Collect Data\n",
    "\n",
    "Drone parameters for DJI MAVIC 2 Zoom\n",
    "\n",
    "- Autopilot (in planning)\n",
    "- Hoover and Capture to minimize image distortion\n",
    "- 5m flight altitude\n",
    "- 5,5m capture distance (image size 7,1m x 5,5m at 5m altitude)  \n",
    "- bright and windless weather conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3rf4acKkK3RL",
    "tags": []
   },
   "source": [
    "## Prepare the Dataset\n",
    "\n",
    "### Labeling for Drone collected data\n",
    "Labeling in PascalVOC format\n",
    "\n",
    "https://github.com/tzutalin/labelImg or https://github.com/openvinotoolkit/cvat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HzZArYBb8P5f"
   },
   "source": [
    "### Parse the dataset\n",
    "\n",
    "The parser loads the annotation file and parses them returning a list of training and validation records. The parsers support multiple formats (including VOC and COCO).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set local data dir path\n",
    "data_dir = Path('/home/martin/projekte/herbst/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'icedata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-39144e01d057>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://simplified-computing.de/herbst21.zip\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdest_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"herbst\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0micedata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'icedata' is not defined"
     ]
    }
   ],
   "source": [
    "# or download dataset\n",
    "url = \"https://simplified-computing.de/herbst21.zip\"\n",
    "dest_dir = \"herbst\"\n",
    "data_dir = icedata.load_data(url, dest_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ft35-rx0L_K4"
   },
   "outputs": [],
   "source": [
    "# Create the parser\n",
    "parser = parsers.VOCBBoxParser(annotations_dir=data_dir / \"annotations_herbst21_training\", images_dir=data_dir / \"image_herbst21_training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HzZArYBb8P5f",
    "tags": []
   },
   "source": [
    "#### Sample dataset \"fridge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TIMdgSb0L5ks"
   },
   "outputs": [],
   "source": [
    "# Download dataset fridge\n",
    "#url = \"https://cvbp-secondary.z19.web.core.windows.net/datasets/object_detection/odFridgeObjects.zip\"\n",
    "#dest_dir = \"fridge\"\n",
    "#data_dir_fridge = icedata.load_data(url, dest_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parser for fridge\n",
    "#parser = parsers.VOCBBoxParser(annotations_dir=data_dir_fridge / \"odFridgeObjects/annotations\", images_dir=data_dir_fridge / \"odFridgeObjects/images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B3Wv6q39JN59"
   },
   "outputs": [],
   "source": [
    "# Parse annotations to create records\n",
    "train_records, valid_records = parser.parse()\n",
    "parser.class_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3rf4acKkK3RL",
    "tags": []
   },
   "source": [
    "### Explore Date\n",
    "\n",
    "Using IceVision Dashboard\n",
    "\n",
    "https://pypi.org/project/icevision-dashboards/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1XiQ6xU2hf2f"
   },
   "source": [
    "### Creating datasets with agumentations and transforms\n",
    "\n",
    "To the training set we apply the Albumentation's default `aug_tfms`. It randomly applies broadly useful transformations including rotation, cropping, horizintal flips, and more. \n",
    "\n",
    "The validation set is only resized (with padding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "z_Au4CUgrqU_"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tfms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f7584157397c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# size is set to 384 because EfficientDet requires its inputs to be divisible by 128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimage_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2048\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_tfms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtfms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maug_tfms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpresize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtfms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mvalid_tfms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtfms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_and_pad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtfms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tfms' is not defined"
     ]
    }
   ],
   "source": [
    "# Transforms\n",
    "# size is set to 384 because EfficientDet requires its inputs to be divisible by 128\n",
    "image_size = 2048\n",
    "train_tfms = tfms.A.Adapter([*tfms.A.aug_tfms(size=image_size, presize=512), tfms.A.Normalize()])\n",
    "valid_tfms = tfms.A.Adapter([*tfms.A.resize_and_pad(image_size), tfms.A.Normalize()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1XiQ6xU2hf2f"
   },
   "source": [
    "We then create `Datasets` for both. The dataset applies the transforms to the annotations (bounding boxes) and images in the data records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y-BnJ71aD7Uh"
   },
   "outputs": [],
   "source": [
    "# Datasets\n",
    "train_ds = Dataset(train_records, train_tfms)\n",
    "valid_ds = Dataset(valid_records, valid_tfms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "60Aiw35DFoCM"
   },
   "source": [
    "#### Understanding the transforms\n",
    "\n",
    "The Dataset transforms are only applied when we grab (get) an item. Several of the default `aug_tfms` have a random element to them. For example, one might perform a rotation with probability 0.5 where the angle of rotation  is randomly selected between +45 and -45 degrees.\n",
    "\n",
    "This means that the learner sees a slightly different version of an image each time it is accessed. This effectively increases the size of the dataset and improves learning.\n",
    "\n",
    "We can look at result of getting the 0th image from the dataset a few times and see the differences. Each time you run the next cell, you will see different results due to the random element in applying transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "id": "mp12p4uihf2r",
    "outputId": "2204c9e6-74e8-4c82-ab84-3752f9f86b7b"
   },
   "outputs": [],
   "source": [
    "# Show an element of the train_ds with augmentation transformations applied\n",
    "samples = [train_ds[0] for _ in range(3)]\n",
    "show_samples(samples, ncols=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tIh7-PHvaYip"
   },
   "source": [
    "## Select a library, model, and backbone\n",
    "\n",
    "In order to create a model, we need to:\n",
    "* Choose one of the **libraries** supported by IceVision\n",
    "* Choose one of the **models** supported by the library\n",
    "* Choose one of the **backbones** corresponding to a chosen model\n",
    "\n",
    "You can access any supported models by following the IceVision unified API, use code completion to explore the available models for each library.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iyAqLEVDaYiq"
   },
   "source": [
    "## Creating a model\n",
    "Selections only take two simple lines of code. For example, to try the mmdet library using the retinanet model and the resnet50_fpn_1x backbone  could be specified by:\n",
    "```\n",
    "model_type = models.mmdet.retinanet\n",
    "backbone = model_type.backbones.resnet50_fpn_1x(pretrained=True)\n",
    "```\n",
    "As pretrained models are used by default, we typically leave this out of the backbone creation step.\n",
    "\n",
    "You can easily pick which option you want to try by setting the value of `selection`. This shows you how easy it is to try new libraries, models, and backbones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cn-Jd69CaYir"
   },
   "outputs": [],
   "source": [
    "# Just change the value of selection to try another model\n",
    "\n",
    "selection = 4\n",
    "\n",
    "extra_args = {}\n",
    "\n",
    "if selection == 0:\n",
    "  model_type = models.mmdet.vfnet\n",
    "  backbone = model_type.backbones.resnet50_fpn_mstrain_2x\n",
    "\n",
    "elif selection == 1:\n",
    "  model_type = models.mmdet.retinanet\n",
    "  backbone = model_type.backbones.resnet50_fpn_1x\n",
    "  # extra_args['cfg_options'] = { \n",
    "  #   'model.bbox_head.loss_bbox.loss_weight': 2,\n",
    "  #   'model.bbox_head.loss_cls.loss_weight': 0.8,\n",
    "  #    }\n",
    "  \n",
    "elif selection == 2:\n",
    "  # The Retinanet model is also implemented in the torchvision library\n",
    "  model_type = models.torchvision.retinanet\n",
    "  backbone = model_type.backbones.resnet50_fpn\n",
    "\n",
    "elif selection == 3:\n",
    "  model_type = models.ross.efficientdet\n",
    "  backbone = model_type.backbones.tf_lite0\n",
    "  # The efficientdet model requires an img_size parameter\n",
    "  extra_args['img_size'] = image_size\n",
    "\n",
    "elif selection == 4:\n",
    "  model_type = models.ultralytics.yolov5\n",
    "  backbone = model_type.backbones.small\n",
    "  # The yolov5 model requires an img_size parameter\n",
    "  extra_args['img_size'] = image_size\n",
    "\n",
    "model_type, backbone, extra_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UJEGLZvwUqFC",
    "outputId": "9b801314-1884-47ea-dfc4-585a0d2c3027"
   },
   "outputs": [],
   "source": [
    "backbone.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KZRLnu2bo40m"
   },
   "source": [
    "Now it is just a one-liner to instantiate the model. If you want to try another *option*, just edit the line at the top of the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VN4giweqD7Un"
   },
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "model = model_type.model(backbone=backbone(pretrained=True), num_classes=len(parser.class_map), **extra_args) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MjrcofdPrDgL"
   },
   "source": [
    "## Data Loader\n",
    "\n",
    "The Data Loader is specific to a model_type. The job of the data loader is to get items from a dataset and batch them up in the specific format required by each model. This is why creating the data loaders is separated from creating the datasets.\n",
    "\n",
    "We can take a look at the first batch of items from the `valid_dl`. Remember that the `valid_tfms` only resized (with padding) and normalized records, so different images, for example, are not returned each time. This is important to provide consistent validation during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rth_fUmwD7Ut"
   },
   "outputs": [],
   "source": [
    "# Data Loaders\n",
    "train_dl = model_type.train_dl(train_ds, batch_size=1, num_workers=1, shuffle=True)\n",
    "valid_dl = model_type.valid_dl(valid_ds, batch_size=1, num_workers=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AzA6y3FmiA-L"
   },
   "outputs": [],
   "source": [
    "# show batch\n",
    "model_type.show_batch(first(valid_dl), ncols=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xpj6XlBYfEi1"
   },
   "source": [
    "## Metrics\n",
    "\n",
    "The fastai engine collect metrics to track progress during training. IceVision provides metric classes that work across the engines and libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XMgHITR3fEi2"
   },
   "outputs": [],
   "source": [
    "metrics = [COCOMetric(metric_type=COCOMetricType.bbox)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WRT_bkcBD7U4"
   },
   "source": [
    "## Training\n",
    "\n",
    "IceVision is an easy to use computer vision framework plugged into DL learning engines such as [fastai2](https://github.com/fastai/fastai2).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Py_DLC0zD7U6"
   },
   "source": [
    "### Training using fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3vwXZIfaFoCU"
   },
   "outputs": [],
   "source": [
    "learn = model_type.fastai.learner(dls=[train_dl, valid_dl], model=model, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "Q9XEUqn4FoCW",
    "outputId": "1e6732b1-d345-4428-d407-fad34f047a1c"
   },
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "\n",
    "# For Sparse-RCNN, use lower `end_lr`\n",
    "# learn.lr_find(end_lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 727
    },
    "id": "x2nhyfSPD7VF",
    "outputId": "0a6795bd-7edf-491d-d8a7-f86b6ee81eed"
   },
   "outputs": [],
   "source": [
    "learn.fine_tune(20, 0.047, freeze_epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uca3AeDiS6id"
   },
   "source": [
    "## Using the model - inference and showing results\n",
    "\n",
    "The first step in reviewing the model is to show results from the validation dataset. This is easy to do with the `show_results` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-1HdqrZFS41s",
    "outputId": "68936b0e-5ba5-4775-a829-87b446ab249e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_type.show_results(model, valid_ds, detection_threshold=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3RiEWszY0HHg"
   },
   "source": [
    "### Prediction\n",
    "\n",
    "Sometimes you want to have more control than `show_results` provides. You can construct an inference dataloader using `infer_dl` from any IceVision dataset and pass this to `predict_dl` and use `show_preds` to look at the predictions.\n",
    "\n",
    "A prediction is returned as a dict with keys: `scores`, `labels`, `bboxes`, and possibly `masks`. \n",
    "\n",
    "Prediction functions that take a `detection_threshold` argument will only return the predictions whose score is above the threshold.\n",
    "\n",
    "Prediction functions that take a `keep_images` argument will only return the (tensor representation of the) image when it is `True`. In interactive environments, such as a notebook, it is helpful to see the image with bounding boxes and labels applied. In a deployment context, however, it is typically more useful (and efficient) to return the bounding boxes by themselves.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KCEldM3baYi1"
   },
   "source": [
    "> NOTE: For a more detailed look at inference check out the [inference tutorial](https://airctic.com/dev/inference/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "42289b108d364e48ae7eee9bd1032dba",
      "844c8f930fe34dc19ff908fe597ff3fc",
      "1e2bdf37f8784377b24daf099a5d91f6",
      "f0c80c9ca08a4a3d9bf35aaf4bd13fca",
      "3fdadc1355674d64920f766864bed43e",
      "2b10aa9d167b4e1397f16ba28be358d8",
      "90d2da749ce8483a93495af45ace9195",
      "09662116e2b1471d85be9ae23cc7c3a5",
      "5f30d73f317c485296ab8034e59d0fd4",
      "5cf612853b614197a27301b436647953",
      "29cc25458e5a422d8466c7c378893fff"
     ]
    },
    "id": "EDVydic9wbje",
    "outputId": "b826b595-cd8b-46dd-a396-1d1bf0cbb2ec",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "infer_dl = model_type.infer_dl(valid_ds, batch_size=4, shuffle=False)\n",
    "preds = model_type.predict_from_dl(model, infer_dl, keep_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "YYYBiC7QjQJs",
    "outputId": "a0373994-0432-44ad-ac1a-aec9431e3f90"
   },
   "outputs": [],
   "source": [
    "show_preds(preds=preds[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3rf4acKkK3RL",
    "tags": []
   },
   "source": [
    "## Localization\n",
    "\n",
    "Calculate GPS coordinates for detected objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install exif -q\n",
    "from exif import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image\n",
    "img_path = '/home/martin/projekte/herbst/data/image_herbst21_training/DJI_0252.JPG'\n",
    "img = Image(img_path)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gps coordinates\n",
    "\n",
    "# convert to decimal coordinates\n",
    "def decimal_coords(coords, ref):\n",
    " decimal_degrees = coords[0] + coords[1] / 60 + coords[2] / 3600\n",
    " if ref == \"S\" or ref == \"W\":\n",
    "     decimal_degrees = -decimal_degrees\n",
    " return decimal_degrees\n",
    "\n",
    "decimal_coords(img.gps_longitude, img.gps_longitude_ref), decimal_coords(img.gps_latitude, img.gps_latitude_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image dimensions\n",
    "img.pixel_x_dimension, img.pixel_y_dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3rf4acKkK3RL",
    "tags": []
   },
   "source": [
    "## Deploy\n",
    "\n",
    "as WebApp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3rf4acKkK3RL",
    "tags": []
   },
   "source": [
    "## Monitor\n",
    "\n",
    "via Weights and Biases"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "getting_started_object_detection.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "metadata": {
   "interpreter": {
    "hash": "7ce67d5d6720b587639daecff2fd8ea5482dfc1f4d2c40a21ebaeb984105fce4"
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "608px",
    "left": "1489px",
    "top": "90px",
    "width": "398.875px"
   },
   "toc_section_display": false,
   "toc_window_display": true
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "09662116e2b1471d85be9ae23cc7c3a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1e2bdf37f8784377b24daf099a5d91f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_90d2da749ce8483a93495af45ace9195",
      "placeholder": "​",
      "style": "IPY_MODEL_2b10aa9d167b4e1397f16ba28be358d8",
      "value": "100%"
     }
    },
    "29cc25458e5a422d8466c7c378893fff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2b10aa9d167b4e1397f16ba28be358d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3fdadc1355674d64920f766864bed43e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_29cc25458e5a422d8466c7c378893fff",
      "placeholder": "​",
      "style": "IPY_MODEL_5cf612853b614197a27301b436647953",
      "value": " 7/7 [00:01&lt;00:00,  5.30it/s]"
     }
    },
    "42289b108d364e48ae7eee9bd1032dba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1e2bdf37f8784377b24daf099a5d91f6",
       "IPY_MODEL_f0c80c9ca08a4a3d9bf35aaf4bd13fca",
       "IPY_MODEL_3fdadc1355674d64920f766864bed43e"
      ],
      "layout": "IPY_MODEL_844c8f930fe34dc19ff908fe597ff3fc"
     }
    },
    "5cf612853b614197a27301b436647953": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5f30d73f317c485296ab8034e59d0fd4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "844c8f930fe34dc19ff908fe597ff3fc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "90d2da749ce8483a93495af45ace9195": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f0c80c9ca08a4a3d9bf35aaf4bd13fca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5f30d73f317c485296ab8034e59d0fd4",
      "max": 7,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_09662116e2b1471d85be9ae23cc7c3a5",
      "value": 7
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
